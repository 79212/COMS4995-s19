<!DOCTYPE html>
<html>
  <head>
    <title>Tools and Infrastructure</title>
    <meta charset="utf-8">
    <style>
        @import url(https://fonts.googleapis.com/css?family=Garamond);
        @import url(https://fonts.googleapis.com/css?family=Muli:400,700,400italic);
        @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);
      </style>
      <link rel="stylesheet" href="../style.css">
  </head>
  <body>
    <textarea id="source">

class: center, middle

### W4995 Applied Machine Learning

# Tools and Infrastructure

01/28/19

Andreas C. Müller

???

Hey. Welcome to the second lecture on applied machine learning. Last
week we talked a bit about very general and high-level issues in machine
learning. Today, we’ll go right down to the metal.
We’ll talk about version control, in particular git, about testing,
continuous integration and about documentation.
Also, I apologize in advance for the slides. There’s a lot of bullet
points and few diagrams and I don’t really like that.
---

class: middle

# So you think you know git?

???

So this first part is about git. I assume you all know about git. Who
here has not used git so far?
If you haven’t this might be a bit steep for you, and you should read
up on it later. Let me know if I’m going to fast.
I assume that you know what version control is and why it’s
important. You should really use version control any time you work on
any code or any other document. And it looks like we’ll have to use
git for now and some time to come.
So you all have used git, but who of you thinks they understand git? Ok
I’ll keep you in mind and ask you trick questions along the way.

---

class: center, middle

![:scale 40%](images/git_xkcd.png)

???
Here’s a comic from xkcd that might seem familiar. I know many people
that use git by just memorizing some commands and if things go south,
they just delete the repository and start fresh.
Who of you have done that? I certainly have.
The goal of today is that you never have to throw your hands up ever
again.

---

class: center, middle

![:scale 40%](images/torvalds_ducreux.jpg)

???
Personally I like to think that git was a practical joke played on the
open source community by Linux Torvals.
Unfortunately, I think the real issue is that kernel developers, genius
as they might be, are not the best at creating user interfaces. Git is
great, but the user interface is horrible. But let’s try and understand
what’s going on.

---

# Version Control with Git


## What is version control?

![do you need git](images/do-you-need-git.png)
---

## Why do I care about the history of a project?

![final_doc](images/final_doc.jpg)
---
## Configuration


```bash
git config --global user.name "Andreas Mueller"
git config --global user.email "amueller@nyu.edu"
git config --global color.ui "auto"
git config --global core.editor "nano"
```

- git command format: git verb
- verb: config
    - who you are
- --global 
    - apply everywhere
- color: color code output
- editor: set default editor 

You can change these setting at any time.
Show your configuration:


```bash
git config --list
```

---

## Creating a repository

- make a directory called planets
- cd into planets directory


```bash
cd /tmp
rm -rf planets
mkdir planets
cd planets
```


```bash
git init
```

- make planets directory a repository 


```bash
ls -a

```

- .git directory is where git stores the history of the project



```bash
git status
```
---

## Tracking Changes to Files

- Create a file to track
    - Open your text editor
    - Type: cold and dry but everything is my favorite color
    - save file as mars.txt
- Check in with git

- start tracking file

- Record current state

    - ``-m`` : commit message inline

---

## Exercise 1:

- Create a file called jupiter.txt with a sentence about jupiter in your planets directory
- start tracking and record the current state of jupiter.txt
- Put your green post-it up when you are done


```bash
touch filename
```


```bash
git status
git add filename
git commit -m "commit message"
```
---

## Viewing your history


```bash
git log
```
---

## Changing a File


Open your mars.txt file and add:
>The two moons may be a problem for Wolfman

Check the status of your files


```bash
echo "The two moons may be a problem for Wolfman" >> mars.txt
```


```bash
git status
```

View the changes you made


```bash
git diff mars.txt
```

Tell git which files you want to record changes in


```bash
git add mars.txt
```

Save changes to revision history


```bash
git commit -m "concerns about Mars' moons"
```
---

##  What are we doing?

![git staging area](images/git-staging-area.png)
---


## A note on viewing changes

     
Changes between working directory and what was last staged


```bash
git diff
```

Changes between staging area and last commit


```bash
git diff --staged
```

---

## Referencing different versions

- Shorthand for different versions of a repository (refers to commits)
    - Current Version (most recent commit): ``HEAD``
    - Version before current: ``HEAD~1``
    - Version before that: ``HEAD~2``
- Each of these also has a commit hash
    - use ``git log`` to get appropriate hash

---

## Exploring History

Changes made in the last commit         


```bash
git diff HEAD~1
```

Changes made in the last 2 commits


```bash
git diff HEAD~2
```

Changes made since commit hash...


```bash
git diff 0b0d55e
```

- first 7 characters
- use ``git log`` to find commit you want

---

## Recovering Older Versions

- Overwrite mars.txt:


```bash
echo 'The mummy will like the dry air.' >  mars.txt
cat mars.txt
```

Recover last recorded version:


```bash
git checkout HEAD mars.txt
```

* ``checkout HEAD`` means revert to version in ``HEAD``
* can use commit hash to revert to even older version
* ``mars.txt``: tells git which file to revert
* in ``git status`` they list this option with ``--`` instead of ``HEAD``. This is a shortcut.

---

## What is going on here
![git checkout](images/git-checkout.png)

---

# Git Basics

- Repository

`$ git init`

`$ rm .git`

???
There are some basic units of git that I want to go through. The first
is a repository. What’s a repository?
A folder who’s content we want to track with version control.
And how can you create one?
Run git init in a folder.
And how can you make a folder not a repository any more?
By removing the .git subfolder. That’s it.
A repository is entirely self-contained. There is no service or database
or anything like that, it’s all plain files within that folder. That
also means if you remove the folder, you lose everything if you don’t
have a backup.

The next basic concept is a commit. What’s that?
It’s a snapshot of the state of the folder, with a message attached,
and identified with an ID. It’s also a node in a graph that describes
the history of the snapshot, and usually has one or two parents, and
can have arbitrary many children.
The ID is a hash of the state and all the parents, so if you change
anything, you change the hash and therefore the commit.

The last basic concept I want to talk about is the remote. That’s just
a pointer to another repository, often github, but it could also just be
another folder on your computer.
You can synchronize with that by pushing or pulling changes. 
--


# Collaborating using git & github

---
## Remote repository

- central location everyone can see
- requires network
- github, bitbucket
- public vs private

![git repo first push](images/github-repo-after-first-push.jpg)
---

## Sign into github

- go to github.com
- sign into your account
- Put up a green post-it
---
## Create a new repository

- Press the create a new repo button
![create repo 1](images/create_repo1.jpg)

- Call your repo planets and "create repository"
- Follow the directions to push an existing repository
- put up your green post-it

![create repo 2](images/create_repo2.jpg)

---

## Exercise: Explore your remote repository

- at the top of the page click yourname/planets
- Explore...

![return to repo](images/return_to_repo.jpg)

---
## what is my remote repository?


```bash
git remote -v
```

default nickname: origin
---
# Starting your collaboration

- Find a partner
- Decide who is Dracula and who is Wolfman
- You will be using Dracula's repository
- put up your green post-it
- put up your red post-it if you need a partner
---
## Wolfman: Cloning a repository

- cd out of planets, create a new directory called planets_collab, and cd into it


```bash
cd ../
mkdir planets_collab
cd planets_collab
```

    

- Clone Dracula's repository
    - make sure its set to HTTPS
    
![clone](images/clone.jpg)

- cd into the planets directory you just downloaded
- put up your green post-it
---
## Dracula: adding a collaborator

- Anyone can clone only collaborators can write
- Dracula only:
    - Click settings on the RHS
    ![settings](images/settings.jpg)
    - Click collaborators on the LHS
    ![collaborators](images/collaborators.jpg)
    - Add Wolfman's github username under collaborators


---
## Collaborating


### Dracula

- modify mars.txt
- save your changes
- add and commit your changes
- push your changes to the remote repository
    
> git push origin master

### Wolfman

 - pull down your partner's changes

> git pull origin master

- add a line to the end of mars.txt
- save your changes
- add and commit your changes
- push your changes to the remote repository
    
> git push origin master
---
## Merge without conflict

- Dracula: modify the first line of mars.txt, save, add, and commit
- Wolfman: modify the last line of mars.txt, save, add, and commit
- Dracula: pull down changes from Wolfman
    - you will be asked to save a merge commit message in nano
- Dracula: push your changes to the remote repository
- Wolfman: pull down changes from Dracula and save the commit message
- Wolfman: push your changes to the remote repository



---
## Merge with conflicts

- Dracula: Edit the last line of the mars.txt, save, add, and commit
- Dracula: try to pull down changes from the remote repository

![conflict message](images/conflict_message.jpg)

---
## Resolving Conflicts

- Dracula: open mars.txt
![conflict](images/conflict_file.jpg)


- Dracula: edit mars.txt to look like correct file
    - remove extra text
    - choose which lines you want to keep
- Dracula: save, add, commit, push

---
## Exercise: Repeat for Wolfman

- Wolfman: pull down Dracula's changes
- Dracula: change the first line of jupiter.txt
- Dracula: save, add, commit, push
- Wolfman: change the first line of jupiter.txt, add, commit
- Wolfman: pull down Dracula's changes
    - you will get a conflict
    - open jupiter.txt and edit to look like final version
    - save changes to jupiter.txt
    - add, commit, push


    
---


# Collaborating using git & github


## Remote repository

- central location everyone can see
- requires network
- github, bitbucket
- public vs private

![git repo first push](images/github-repo-after-first-push.jpg)


## Sign into github

- go to github.com
- sign into your account
- Put up a green post-it

## Create a new repository

- Press the create a new repo button
![create repo 1](images/create_repo1.jpg)

- Call your repo planets and "create repository"
- Follow the directions to push an existing repository
- put up your green post-it

![create repo 2](images/create_repo2.jpg)



## Exercise: Explore your remote repository

- at the top of the page click yourname/planets
- Explore...

![return to repo](images/return_to_repo.jpg)

## what is my remote repository?


```bash
git remote -v
```

default nickname: origin

# Starting your collaboration

- Find a partner
- Decide who is Dracula and who is Wolfman
- You will be using Dracula's repository
- put up your green post-it
- put up your red post-it if you need a partner

## Wolfman: Cloning a repository

- cd out of planets, create a new directory called planets_collab, and cd into it


```bash
cd ../
mkdir planets_collab
cd planets_collab
```

    

- Clone Dracula's repository
    - make sure its set to HTTPS
    
![clone](images/clone.jpg)

- cd into the planets directory you just downloaded
- put up your green post-it

## Dracula: adding a collaborator

- Anyone can clone only collaborators can write
- Dracula only:
    - Click settings on the RHS
    ![settings](images/settings.jpg)
    - Click collaborators on the LHS
    ![collaborators](images/collaborators.jpg)
    - Add Wolfman's github username under collaborators



## Collaborating


### Dracula

- modify mars.txt
- save your changes
- add and commit your changes
- push your changes to the remote repository
    
> git push origin master

### Wolfman

 - pull down your partner's changes

> git pull origin master

- add a line to the end of mars.txt
- save your changes
- add and commit your changes
- push your changes to the remote repository
    
> git push origin master

## Merge without conflict

- Dracula: modify the first line of mars.txt, save, add, and commit
- Wolfman: modify the last line of mars.txt, save, add, and commit
- Dracula: pull down changes from Wolfman
    - you will be asked to save a merge commit message in nano
- Dracula: push your changes to the remote repository
- Wolfman: pull down changes from Dracula and save the commit message
- Wolfman: push your changes to the remote repository




## Merge with conflicts

- Dracula: Edit the last line of the mars.txt, save, add, and commit
- Dracula: try to pull down changes from the remote repository

![conflict message](images/conflict_message.jpg)

## Resolving Conflicts

- Dracula: open mars.txt
![conflict](images/conflict_file.jpg)


- Dracula: edit mars.txt to look like correct file
    - remove extra text
    - choose which lines you want to keep
- Dracula: save, add, commit, push


## Exercise: Repeat for Wolfman

- Wolfman: pull down Dracula's changes
- Dracula: change the first line of jupiter.txt
- Dracula: save, add, commit, push
- Wolfman: change the first line of jupiter.txt, add, commit
- Wolfman: pull down Dracula's changes
    - you will get a conflict
    - open jupiter.txt and edit to look like final version
    - save changes to jupiter.txt
    - add, commit, push



- Commit

--

- Remote

---

# Typical Workflow

- Clone

- Branch

- Add, commit, add, commit, add, commit, ...

- Merge / rebase

- Push

???
So here’s a typical workflow for making a change to an existing
project. You clone the project from some remote repository. You change
some files, add them, and commit them.
Then you push them to the remote repository.
That’s more or less what you’ll do with your homework.

The advanced version of this is after cloning you create a branch, you
make all your changes on the branch, and once you’re done, you merge
the changes from your branch into the master branch.

Everybody good so far?
I want to give some basic tips that will help you even with these simple
workflows.

---

# Some tips

- `$ git status`

- Install shell plugins for status and branch (`oh-my-zsh`)

![:scale 90%](images/git_shell_extension.png)

- Set editor, pager and diff-tool (check out meld!)

- Use `.gitignore`

???
You should always call git status, to see what’s happening with your
repository. It will tell you whether you changed anything, and which
branch you’re on.
I actually highly recommend using a plugin for your shell, that will give
you the status in every line. If you use zsh, you can use oh-my-zsh for
example. If you use something else like bash, there are also plenty of
options out there.

You should also set your editor and pager to something that is familiar
to you. The default editor is vim, and if you’re not a vim user, you
might want to change that. It’s also helpful to set up a diff program
that you like. I like meld for example, that allows you to compare whole
folders in a nice way.

You should also use gitignore. It's a simple text file that allows you to
ignore certain files or folders or file types. For example, you could ignore
all .pyc files. Or you could ignore all .ipynb-checkpoints or your dataset
folder.

---

# Git log

![:scale 80%](images/git_log.png)

???
You should also become friends with git log. Git log allows you to
view the history of your repository. It has a couple of very helpful
options. Plain git log will have very long output and show full commit
messages.

If you want short summaries, use oneline.

Often, it’s also useful to annotate branches, which you can do with
A
the decorate option.
If you want to show more than just the branch you’re on, you can use
the all option.

Now it’s a bit hard to track the relations of the different commits,
though, and you might want to use the graph option to show the structure
of the history.

You might want to alias a command like that because it’s rather long
to type, but very informative. I’ll show you an alternative in a bit.

---

class: center, middle

![:scale 50%](images/git_adog.png)

???


---

# Understanding Git

- Working directory

- Repository (Commit graph, history)

- Index (Staging Area)

- Branches

- Head

???
So now, I want to work towards really understanding git, and here
are some lower level concepts that are important. First, the working
directory. That’s the actual current content of the folder on disk.
Then there is a graph of commits, also known as the history. Formally that's called
the repository, though usually I think of the repository as the whole thing. It's a directed
acyclic graph that contains all the changes and contains the information
about the parents of a commit.
Then the index. The index is what's also called the staging area,
it's an intermediate space in which you accumulate changes you want to put in a commit.
Branches are quite simple. They are just pointers to particular commits. They
point to certain commits.
Head is another pointer. Head points to the current active branch. That
is the branch that will be updated if you make a commit. (unless you’re
on no branch, in which case you are headless)
The state of you repository is really much more than the state of the
directory, it’s the state of all of these five things together. And
if you think about commands, you should think about them in terms of
what they do to each of these five.

---
class: compact

# git Commands

.smallest[
- .normal[`git add`]<br />
puts files from working director into staging area (index) If not tracked so far, adds them to tracked files.

- .normal[`git commit`]<br />
commits files from staging area (index) to repository, moves current
branch with HEAD

- .normal[`git checkout [<commit>] [<file>]`]<br />
Set `<file>` in working directory to state at `<commit>` and stages it.

- .normal[`git checkout [-b] <branch>`]<br />
moves HEAD to `<branch>` (-b creates it), changes content of working dir

- .normal[`git reset --soft <commit>`]<br />
moves HEAD to `<commit>` (takes the current branch with it)

- .normal[`git reset --mixed <commit>`]<br />
moves HEAD to `<commit>`,  changes index to be at `<commit>` (but not
working directory)

- .normal[`git reset --hard <commit>`]<br />
moved HEAD to `<commit>`, changes index and working tree to `<commit>`.
]

???
Ok so now, let’s got through some of the commands and talk about what
they do in terms of these five concepts
[read slide]

---
class: center

![:scale 60%](images/git_data_transport.png)

???
I found this data flow diagram online and I think it's quite helpful for a subset of the commands.
It shows how you can propagate changes from the working directory to a remote repository and back.
This is only a small part of all the commands, though. For example reset is missing, and generally
nothing that moves branches or head is here.

---

# Merge

- Fast-forward merge:

![:scale 90%](images/git_fast_forward_merge.png)

- Merge-commits:

![:scale 90%](images/git_merge_commit.png)

???

Now let's talk about the  the more complex operations to the repository or
history, merging and rebasing. They change the commit graph, and possibly the working
tree. I find it most helpful to think of them as graph operations on the repository.

Let's start with merges.
There’s two kinds of merging: feed-forward merges, and merges that
require a commit. If one commit is a descendants of the other and you
merge them, it will be a feed-forward, and just move the branch.
That happens for example if you just pull new changes from a remote
repository that you cloned, if you haven't made any local changes.

However, if one isn’t a descendant of the other, git will create a
“merge commit” that will unite the two, and have both as its
parent. Git will attempt its best but if there’s conflicting changes,
you might need to resolve the conflicts by hand.

---

# Rebase

- Rebase<br/>
![:scale 50%](images/git_rebase1.png)

- Rebase onto<br />
`git rebase --onto master next`
.left-column[
![:scale 80%](images/git_rebase2.png)
]
.right-column[
![:scale 80%](images/git_rebase3.png)
]

???
Rebase is a whole different beast. It allows more or less arbitrary
modifications of the graph, and therefore rewriting history.
You should be aware that if you use rebase, you will change a commit's
hash because the hash depends on the history.
Basically what rebase does is place a range of commits on top of another
commit. If you're on branch A and you do git rebase B (or any other commit),
what will happen is that it will find the common ancestor, take everything
up to that ancestor, and place it on branch B.
You can change the commit that it puts the changes on top of by using
the --onto flag. So if I want to take the last five changes I do git
rebase HEAD~5 --onto B
That will take the common ancestor with HEAD~5, which is HEAD~5, and
place it onto B.


---
# Interactive rebase

`git rebase -i <commit>`

![:scale 66%](images/git_interactive_rebase.png)

???
You can make rebase even more complicated - and powerful, by making it
interactive. While you could make any rebase interactive, it’s most common to
rebase on an ancestor with interactive – in this case a non-interactive rebase would have no
consequences.
For each commit in the range that you want to rebase, interactive rebase
allows you to pick the commit, which is leave it alone, squash it,
which means incorporating it into the previous commit, removing it or
amending it.
Interactive can be useful for cleaning up your history after you worked
on a feature, so that the remaining commits are logical units.

---
class: center, middle
# Squash before Rebase

???
Rebasing can also create conflicts that need to be resolved the same way
as merge conflicts. However, rebasing “plays back” all the commits
that you moved on top of the target commit. That means that you might
have to resolve conflicts on the same file multiple times – which you
probably want to avoid.

A good way to get around that is to squash all the commits you want to
rebase into a single one, and then rebase that single commit. That means
you only have to do conflict resolution once.

So before you do a rebase on a different branch, you might do an
interactive rebase to squash some commits and make conflict resolution easier.

---

# Interactive adding

![:scale 55%](images/git_interactive_add.png)

???
What I find even more important is interactive adding. With git add,
you usually add whole files to the staging area. I rarely ever do
that. Usually I want to check line by line what changes I made and what
changes I want to commit.
Git add -i allows me to through all the different hunks or lines
I changed.
However, the command line interface is a bit clumsy for my taste. Or
maybe I’m just not as used to it.
I prefer a gui, which you can summon with git gui on the command line.

---
class: center, middle

# git gui

![:scale 80%](images/git_gui.png)

???
Git gui is basically an interface for git add and git commit. You can
also use it to push, but not much more.
This is the way I create most of my commits. You can see very easily
which files have changed, see the changes, and stage single lines or
whole files.
Then you enter the commit message here, and click commit.

---
class: center, middle

# gitk

![:scale 80%](images/gitk.png)

???
Another tool that I use all the time is gitk.
This is basically a graphical interface to git log, showing you the
history of your project. But you can also use it as a graphical interface
for reset, and for cherry-picking, which we won’t go into.
Often I run gitk with gitk –all, which will show you all the
branches. This is quite similar to the
Git log –oneline –anotate –graph –all that I did earlier –
but now in a gui!
This is usually how I do resets and how I look at the graph before I do
any merges or rebases.
You can also use gitk to search commit messages, and there are many option
on what to display and how. I mostly use the options to selectively show
some branches that I’m interested in.

---

# reflog
.left-column[
`$ git reflog`
![:scale 100%](images/git_reflog.png)
]
.right-column[
<br \>
![:scale 100%](images/git_simple_merge_graph.png)
]
???
The last command I want to mention is reflog.
Reflog is a very powerful tool that allows you to go through the history
of your project, but not the same was as log. Reflog actually tracks
the changes to HEAD that you do with all the crazy commands that we
talked about.
Log and gitk will only show you commits that are part of branches. If
you do a rebase, for example, all the previous commits are still there,
but not part of a branch any more. Remember, rebasing creates new hashes,
so the rebased commits are different commits.
Imagine you want to go back to some states that are not part of any branch
any more. Reflog allows you to do that. So if you break something during
a rebase, or you lost a commit, you can always find it with reflog!

---
class: center, middle
# Git for ages 4 and up:

https://www.youtube.com/watch?v=1ffBJ4sVUb4

(with play-doh!)

???
For some of you, this was probably too slow, and for some of you, this
was probably too fast.
Who here knew already all of this?
So for those of you who I managed to totally confuse, I recommend you
go through these slides again, and also watch this video. It’s pretty
good, but it’s also pretty long.
And for those of you who though this was wayyy to much detail: this
was still not all the important parts. There’s also tags, and bare
repositories and the stash and cherries...

---
class: center, middle

# Github - just another remote

???
I want to just briefly talk about github.
For the purposes of git, github is just another remote. And it’s really
nothing special. In terms of being a remote, you can replace github with
a usb stick that you hand around.
There is a lot of tools for user management and issue tracking which is
great, but not really central what we’re talking about here. The main
thing that’s different in using github from using any other remote,
is the use of pull requests, and the ability to integrate with remote
services.
For now lets talk about pull requests, we'll come back to the services later.

---
class: center

# Github pull request workflow
<br />
![:scale 50%](images/forks1.png)
???

So what are pull requests for?
Basically they allow you to contribute to a repository to which you
don’t have write permissions.
Let’s say you want to contribute to scikit-learn. Or to the lecture slides.

There’s the main repository, which we usually call "upstream",
scikit-learn/scikit-learn. You want to change something there, but you
don’t have write permissions.

---
class: center

# Github pull request workflow
<br />
![:scale 50%](images/forks2.png)
???

What you can do is "fork" it on github – that’s a github concept,
not a git concept. It’s just a clone that also lives on github.

---
class: center

# Github pull request workflow
<br />
![:scale 50%](images/forks3.png)
???
To actually make any changes, you
can then clone this fork locally, add a feature branch, make changes
and push them.

---
class: center

# Github pull request workflow
<br />
![:scale 50%](images/forks.png)
???

Then you can ask the owner of the repository if they want to merge your
changes. That's a pull request and allows the owner to "pull" in your
changes into the main repository.

So far, so good. Makes mostly sense, I think.
There is a slight oddity in this workflow, though.

---
class: center

# Github pull request workflow
<br />
![:scale 60%](images/forks_master_feature.png)
???

Usually you pull the current status from the master branch,
and make some changes that you want to include. So you always pull master
and push feature branches.
But the code in the upstream repository changes. How do you get
these changes onto your laptop? 
If the original repository gets updated, there is no way to directly update your fork.

---
class: center

# Github pull request workflow
<br />
![:scale 60%](images/forks_master_feature2.png)
???
You have to add upstream as an additional remote, and then you can pull from
there. You can create new features on top, and push the feature branches to
your fork (which is usually the “origin” remote).
But what happens with the master branch on your fork? It never gets
updated and there is no point in pushing to it, so it will just sit there
and rot, staying at the state of the original repository at the time of your fork.
I think that’s kind of weird, but that’s how github works.
So you always pull from upstream to get their changes, and push to
your fork.
---
class: center, middle

# End version control – but github will come back later ;)

???
Ok, so that’s enough version control for now. But we’ll get back to
githubs integration of third party services later.
---
class: center, middle

# Unit Tests and integration tests

???
So last time we talked about how we can guard ourselves against some simple
issues with our syntax checkers, but that doesn’t find all errors, and it
doesn’t tell us if our code works. So we now we’ll talk about unit testing and
integration testing.

Who of you has worked with an automatic testing framework?

What is it for and why would we want it?

---
class: spacious

# Why test?

- Ensure that code works correctly.
- Ensure that changes don’t break anything.
- Ensure that bugs are not reintroduced.
- Ensure robustness to user errors.
- Ensure code is reachable.

???
So yes, we want to make sure that our code is correct. We also want to
make sure that if we rewrite something, it remains correct. If you have
good tests, it is much easier to aggressively refactor your code. If
your tests are passing, everything works!
Another important kind of test is no-regression tests. You found a bug,
you fixed it, and now you want to make sure you don’t re-introduce
it. The easiest way is to write a test that tests for the bug.
You also want to make sure that your program behaves reasonable, even
in edge-cases such as invalid input.
And finally, testing can help you find code that is actually unreachable
by measuring coverage. If you can’t write a test that will reach
a particular part of the code, it’s never executed, and you should
probably think about that.

---
class: center, middle

# Test-driven development?

???
I love tests. But there are some people that love tests even more,
and they practice what’s called test-driven development. Who here has
heard about that?
In test driven development, you write the tests before you write the
code. And there are advantages to that. I don’t usually do that myself.
However, I do test-driven debugging. If I find a bug, I first write a test
that fails if the bug is present. I need to do that later anyhow, because
I need a non-regression test, and it usually makes debugging much easier.
I often do example driven development, where I write down some simple
use-cases and then write implementations to fullfil them.

---

# Types of tests

- Unit tests – function does the right thing.

- Integration tests – system / process does the right thing.

- Non-regression tests – bug got removed (and will not be reintroduced).

???
I usually think of tests in terms of three kinds: unit tests, that test
the smallest possible unit, usually one function.
Then, there’s integration tests, that test that the different parts
of the software actually work together in the right way. That is often
by testing several application scenarios.
And finally, there’s non-regression tests, which can be either a unit
tests, an integration test, or both, but they are added for a specific
scenario that failed earlier, and you’ll accumulate them as your
project ages.

---

# How to test?

- py.test – http://doc.pytest.org

- Searches for all test_*.py files, runs all test_* methods.

- Reports nice errors!

- Dig deeper:
http://pybites.blogspot.com/2011/07/behind-scenes-of-pytests-new-assertion.html

???
There are several frameworks to help you with unit testing in
python. There’s the built-in unittest module, there’s the now somewhat
abandoned nosetests.
For the course we’ll be using the py.test module, which is also what
I’d recommend for any new projects.
What it does is it searches all files starting with `test`, runs them,
and reports a summary.
The tests should contain assert statements, and if any of them fail,
you’ll get an informative error.
This is actually done with a considerable amount of magic, which you
can read up on here, if you’re into rewriting the AST.


---
# Example

.smaller[

```python
# content of test_sample.py

def inc(x):
    return x + 2

def test_answer():
    assert inc(3) == 4
```
]

![:scale 60%](images/pytest_failure.png)

???
So here I have a slightly modified version of the example from the pytest
website. We have a function called inc that’s supposed to increment
a number. But there’s a bug: it adds two instead of one.
And we have a test, which is called `test_answer`, that calls the
inc function with the number three and checks if three is correctly
incremented.
If we call py.test on this file, or on the folder of this file, py.test
will run the `test_answer` function - because it starts with `test_`.
It tells us it ran one test, and that test failed. We also get a traceback
showing us the line and what the actual value was. We got 5 instead of 4.
Depending on how much you know about programming, this error message should
come as a bit of a surprise to you. The assert only gets a boolean,
but pytest actually unpacks the `False` and gives us more information.

---

# Example

```python
# content of test_sample.py

def inc(x):
    return x + 1


def test_answer():
    assert inc(3) == 4
```

![:scale 70%](images/pytest_passed.png)

???
So now we go back and fix our increment function, and run py.test
again. This time, it tells us the tests passed.
Does that mean the function is correct?
No, but we could test more. How? We could do the same with more
numbers. Tests are usually only necessary, not sufficient
for correctness.

Usually all test for a project are in a separate file or even a separate
folder. In this example we had the test and the function to be tested
in the same file, but that’s not good style.
The actual implementation should be completely separate from the tests.


---

# Test coverage
.smaller[
.left-column[
```python
# inc.py
def inc(x):
    if x < 0:
        return 0
    return x + 1


def dec(x):
     return x - 1
```
]

.right-column[
```python
# test_inc.py
from inc import inc

def test_inc():
     assert inc(3) == 4
```
]
]

.reset-column[
![:scale 70%](images/pytest_coverage1.png)]
???
Here’s a more complex example, with inc.py containing two functions
and test_inc.py containing the same test. I added an if into the inc
function, and a dec function.
If we run the test, they still pass. But clearly we’re not testing
everything. In this example, it’s easy to see that we don’t test the
if branch and we don’t test the dec function at all. If you project
is larger and more complex, it’s much harder to figure out whether
you covered all the edge-cases, though.
That’s where test coverage tools come in handy.

---

# Test coverage
.smaller[
.left-column[
```python
# inc.py
def inc(x):
    if x < 0:
        return 0
    return x + 1


def dec(x):
     return x - 1
```
]

.right-column[
```python
# test_inc.py
from inc import inc

def test_inc():
     assert inc(3) == 4
```
]]

.reset-column[
![:scale 50%](images/pytest_coverage2.png)
]

???
So instead of just calling py.test, we specify --cov inc, which means
we want to test the coverage of the inc module or file.
Now we get a coverage report that tells us that out of the 6 statements
in inc.py, two were not covered, resulting in 67% coverage.
There are several ways to figure out which lines we missed, I like the
html report the most.


---

# HTML report

.larger[
```bash
$ py.test --cov inc --cov-report=html
```
]

.left-column[![:scale 100%](images/pytest_html_report1.png)]
.right-column[![:scale 100%](images/pytest_html_report2.png)]

???
So we specify --cov-report=html, and py.test will create a html report
for us. We get an overview that contains the same information as before,
but we’ll also get a detailed view of inc.py, which shows us which
lines we covered and which lines we missed.
And now we can clearly see that we never reached the return 0 line in
inc and we never tested dec.

Whenever your write tests, you should make sure they cover all cases in
your code, in particular the different algorithmic pieces. Covering all
error messages is possibly not as important. You should usually aim for
coverage in the high nineties.

If you look at projects on github, you can often see a badge that
says “coverage X %”, showing the code coverage. These badges are
actually automatically generated, and next I want to talk about how
that’s done.


---
class: center, middle

# Continuous integration (with GitHub)

???
This is the magic of continuous integration, which I mentioned already last time.
Continuous integration is a general paradigm in software engineering, of
automatically running integration tests whenever you change your software.
I want to talk about it in particular in the context of github, because
that’s what you’ll likely be using, both here and later in industry
– at least in a startup. If you go to google or facebook of amazon,
they all have their own frameworks, but the same principles apply.

They often have even more involved systems, like continuous deployment,
which actually automattically puts new code into production if it passes
tests. We're not gonna talk about that here. Continuous deployment gets
somewhat trickier with machine learning algorithms.

---

# What is Continuous integration?

- Run command on each commit (or each PR).
- Unit testing and integration testing.
- Can act as a build-farm (for binaries or documentation).
- requires clear declaration of dependencies.
- Build matrix: Can run on many environments.
- Standard serviced: TravisCI, Jenkins and CircleCI

???
Ok so what’s continuous integration in more detail?
It runs some sequence of commands on a cloud machine every time a commit
is made, either just for a particular branch, or for each pull request.
Usually the command is just running the test suit, but you can also
check coverage or style or build binaries or rebuild your documentation.
This is done on a clean cloud machine, so you need to be very explicit
about your dependencies, which is good. You can specify a build matrix
of different systems you want to run, such as linux and os X, different
versions of Python and different versions of the dependencies, like
older and newer numpy versions.
There are some standard services out there that are free for open
source and educational purposes, travis, jenkins and circle are some of
them. We’ll use travis for this course.


---

# Benefits of CI

- Can run on many systems
- Can’t forget to run it
- Contributor doesn’t need to know details
- Can enforce style
- Can provide immediate feedback
- Protects the master branch (if run on PR)

???
So what’s the benefits of doing this?
You can run it on many systems, and in parallel. You might not have all
the operating systems that you want it to run on, and you might not go
through the hassle of trying out every patch on every machine.
Because CI is automatic, you can’t forget to run it. There’s
github integration that will give you a red x or a green check mark,
and everybody will know whether your commit was ok or not.
You can make a change to a package without knowing all the requirements
and even without knowing how to run the tests. The CI will complain if
you broke something.
And you get immediate feedback while you’re working, because tests
are run every time you commit!
Most projects will only merge pull requests that pass CI, and that means
the master branch can not break and will always be in working condition,
which is important.

---

# What does it do?

- Triggered at each commit / push
- Sets up a virtual machine with your configuration.
- Pulls the current branch.
- Runs command. Usually: install, then test.
- Reports success / Failure to github.

???
Ok so let’s go through the steps that the CI performs.
Let’s say you configured travis for one of your branches on github. If
you push to that branch, travis will be triggered.
A virtual machine will be set up with the configuration that you
specified. The machine pulls your current version of the project. If
it’s a pull request, it might also use the code that would be the result
of a merge, so it would be your changes applied to the current project.
Then some commands are run that you can specify. Usually these are
installing the package, possibly including dependencies, and then running
the test suite.
After the test-suite runs, it will report back to github.

---
# Setting up TravisCI

.smaller[
- Create account linked to your github account: http://travis-ci.org<br />
![:scale 60%](images/travis_activate.png)
- Check out docs at https://docs.travis-ci.com

```yaml
language: python
python:
  - "2.7"
  - "3.4"
  - "3.5"
  - "3.6"
  - "3.7"
  - "nightly"
# command to install dependencies
install:
  - pip install -r requirements.txt
# command to run tests
script:
  - pytest # or py.test for Python versions 3.5 and below

```
]

???
So in general to set up travis you have to create an account that is
linked to your github account, and enable travis-ci on the repository
you want.
For public repositories and students its free, otherwise you have to
pay for the service.
For the homework you'll need to enable this for your repo.

There a docs online at this website, and the only thing you need to do
is create a .travis.yml file with the configuration.
Here, we specify the versions of python we want to run, the install
command, and the final command.
This will run pip install with a requirements file. You could also run
python setup.py install,or specify requirements here directly.


---

# Using Travis

- Triggered any time you push a change
- Integrated with Pull requests
- Try a pull request on your own repository!

???
Travis is run automatically each time you push a change, so in the
homework, push a change and then see the status page.
You can also do a pull request on your own repository, so you can see the
pull request integration. It’s pretty cool and you should try it out.

---
class: center, middle

# Documentation

???
So now, we come to the last bit that is about general software development,
documentation. We talked earlier about how important it is to write readable
code.  But no code is perfectly documenting itself. You definitely need to
write additional documentation.
Also, many people don’t like digging through code, so some documentation
that’s more easily accessible is helpful.

I decided to take this off the homework this year, because people were struggling
a lot with setting up the infrastructure last year. That's a bit
unfortunate, because it's really cool once you see all the pieces coming together.

---

# Why document?

- Allow people to use the code without reading it.
- Your code is harder to understand than you think.
- Input types and output types are unclear in dynamic languages.
- Often implicit assumptions about input.

???
So why do we document?
The most obvious reason is that you want other people to use your code,
and most people don't want to read the full implementation of a function
before they can use it. You can document the functionality, interface
and assumptions, and anyone can use your code, without having to dig
through all the details.
Even if someone wants to read the code, documentation makes reading the code
easier. Others will thank you, including your future self.
While you should document any function or class in any language, in
dynamically typed languages in particular, it’s often unclear what the
assumptions about the input are, and what the type of the output is. So
these are really crucial to document.
And if the input is some complex object like a dictionary or a custom
class, often you make assumptions about the content of this object that
are not obvious from the code.

---
# Python documentation standards
.compact[
.smaller[
- PEP 257 for docstrings for class, methods and functions
```python
def inc(x):
    """Add one to a number.

    This function takes as argument a number, and adds one to it.
    The result is returned.
    """
    if x < 0:
        return 0
    return x + 1
```
- Additional inline documentation
```python
    if x < 0:
        # x is less than zero
        return 0
    return x + 1
```
]]
???
Python has some standards for documentation, described in pep  257.
Every class, method or function should have a docstring, at the very
least all public ones.
These are particularly helpful because they can be easily viewed inside
a python session or with Jupyter Notebook.
For docstrings we use triple quotes, with a single line
Explanation in the first line, then an empty line, then a more detailed
explanation.
This docstring is stored in the `__doc__` attribute of the object.

In addition to that, you can use inline documentation when you think it
might be useful, using the pound.

---

# NumpyDoc format

See

.smaller[https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt]

```python
"""
Parameters
-----------
x : type
    Description of parameter x.
"""
```

???
You might have noticed that the python folks like standards. In the
data science community there’s a stricter standard, which is the
numpydoc format.
It’s what you’ll see in numpy, scipy, pandas and scikit-learn for
example.
The documentation has several sections for Parameters, return values,
examples, notes and more.
The most important parts are the parameters and return values, which
you should document as you can see here.
A detailed description of the documentation format is in the doc I linked
to. You should always document all parameters and all return values.
This documentation is in restructured text format, which we’ll come
to in a bit.
This format is a bit idiosyncratic with a space before the colon, but
it’s important that you actually stick to this.

---

# NumpyDoc example

.left-column[
![:scale 95%](images/numpydoc_multinomial_nb.png)
]
.right-column[
![:scale 95%](images/numpydoc_fit.png)
]

???
Here you can see two examples from scikit-learn. On the left is the
docstring for the MultinomialNB class. The class docstring follows
the class definition, and the parameters are the parameters to the
init function.
You can see parameters, attributes, examples, notes and references.

Next to it is the fit method, which just has a one-line description and
then the parameters and return values.
You can see that the type descriptions can get pretty specific, giving
the matrix shapes.

You might ask why we’re using this specific format and why we’re
using restructured text. And the answer to this is sphinx.

---
class: middle

# Questions ?

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script>
    // Config Remark
    remark.macros['scale'] = function (percentage) {
        var url = this;
        return '<img src="' + url + '" style="width: ' + percentage + '" />';
    };
    config_remark = {
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true,
        ratio: "16:9"
    };
      var slideshow = remark.create(config_remark);

    // Configure MathJax
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] /* removed 'code' entry*/
    }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
    </script>
  </body>
</html>
